{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Data Cleaning and Transformation\n",
    "(Add description here)\n",
    "\n",
    "[Factors of Academic Success Survey](https://forms.gle/vJcqWct3swRasCbAA \"Link to Google Forms\")\n",
    "\n",
    "\n",
    "#### The two demographics that were surveyed:\n",
    "- A Drum Corps Facebook Page\n",
    "- People and friends who follow me on my social media accounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries and survey results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read survey spreadsheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"Google Forms Spreadsheets\")\n",
    "\n",
    "for _, _, filenames in os.walk(os.getcwd()):\n",
    "    surveydata = pd.read_excel(filenames[0])\n",
    "    for f in filenames[1:]:\n",
    "        surveydata = pd.merge(left=surveydata, right=pd.read_excel(f), how=\"outer\")\n",
    "\n",
    "surveydata.columns = map(str.lower, surveydata.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the average amount of sleep for each person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_bed_times(column, dataf=surveydata):\n",
    "    \"\"\"\n",
    "    Corrects incorrect AM/PM selection for given column name\n",
    "    \n",
    "    Accepts string and DataFrame (default: surveydata)\n",
    "    Returns dt.time Series\n",
    "    \n",
    "    \"\"\"\n",
    "    if column == \"go_to_bed\":\n",
    "        return pd.Series([dt.time(np.abs(time.hour - 12), time.minute, 0) \n",
    "                          if 6 < time.hour < 18 \n",
    "                          else time \n",
    "                          for time in dataf[column]])\n",
    "    \n",
    "    elif column == \"up_from_bed\":\n",
    "        return pd.Series([dt.time(np.abs(time.hour - 12), time.minute, 0) \n",
    "                          if time.hour > 18 \n",
    "                          else time \n",
    "                          for time in dataf[column]])\n",
    "    \n",
    "surveydata[\"go_to_bed\"], surveydata[\"up_from_bed\"] = clean_bed_times(\"go_to_bed\"), clean_bed_times(\"up_from_bed\")\n",
    "\n",
    "\n",
    "def time_to_datetime(column, dataf=surveydata):\n",
    "    \"\"\"\n",
    "    Converts dt.time values to dt.datetime values based on the bedtime or waketime\n",
    "    \n",
    "    Accepts string and DataFrame (default: surveydata)\n",
    "    Returns dt.datetime Series\n",
    "\n",
    "    \"\"\"\n",
    "    # Insert date\n",
    "    time_day = pd.Series([\"2000/01/02 \" \n",
    "                          if (column == 'up_from_bed' or (column == 'go_to_bed' and dataf[column][i].hour < 5)) \n",
    "                          else \"2000/01/01 \" \n",
    "                          for i in range(dataf.shape[0])]).astype(str)\n",
    "    \n",
    "    # Convert time values to strings\n",
    "    time_time = dataf[column].astype(str)\n",
    "    \n",
    "    # Concat date and time and convert to datetime object    \n",
    "    return (time_day + time_time).apply(lambda x: dt.datetime.strptime(x, \"%Y/%m/%d %H:%M:%S\"))\n",
    "\n",
    "# Calculate and insert column into the dataset and convert timedelta to hours\n",
    "surveydata.insert(23, 'avg_sleep_hours', (time_to_datetime('up_from_bed') - time_to_datetime('go_to_bed')).apply(lambda x: x.seconds / 3600))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map college majors column into seperate categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For some reason my regex lookaheads and lookbehinds wont work, something to figure out later\n",
    "surveydata.insert(5, 'major_cat', surveydata.major.fillna(\"Undecided\"))\n",
    "\n",
    "mapping_majors = {\"Undecided\":r\"general|no\\sclue|undecided\", \"Medical\":r\"medi|pharmacy|nursing\", \"Music\":r\"music\", \"Business\":r\"account|manage|info\", \n",
    "                  \"Science\":r\"zoo|biology|physical|animal|agri|kinesi|science\", \"Technology\":r\"tech|computer(?!info)\", \n",
    "                  \"Engineering\":r\"(?<!medical)engineer|aviation\", \"Math\":r\"data|physics|math|economics\",\n",
    "                  \"Fine Arts\":r\"art|picture|culinary|history|tourism|soci|child\", \"Trades\":r\"welding\"}\n",
    "\n",
    "for cat in [\"Undecided\", \"Medical\", \"Music\", \"Business\", \"Science\", \"Technology\", \"Engineering\", \"Math\", \"Fine Arts\", \"Trades\"]:\n",
    "    surveydata.loc[surveydata.major_cat.str.contains(mapping_majors[cat], flags=re.IGNORECASE), 'major_cat'] = cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare SAT and ACT scores and keep the highest one as a converted SAT score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def act_to_sat(act):\n",
    "    \"\"\"\n",
    "    Converts given ACT test score to equivalent SAT test score\n",
    "    \n",
    "    Accepts string, int, float, or np.NaN\n",
    "    Returns int or np.NaN\n",
    "    \n",
    "    \"\"\"\n",
    "    act_sat = {'36':1590, '35':1540, '34':1500, '33':1460, '32':1430, '31':1400, '30':1370, '29':1340, '28':1310, '27':1280, '26':1240, '25':1210, '24':1180, '23':1140, '22':1110, '21':1080, '20':1040, '19':1010, '18':970}\n",
    "    if np.isnan(act):\n",
    "        return np.NaN\n",
    "    else:\n",
    "        score = str(int(act))\n",
    "        if score in act_sat:\n",
    "            return act_sat[score]\n",
    "        else:\n",
    "            return np.NaN\n",
    "        \n",
    "# Insert column and clean values\n",
    "surveydata.insert(11, 'converted_sat', surveydata.act.apply(act_to_sat))\n",
    "surveydata[['converted_sat', 'sat']] = surveydata[['converted_sat', 'sat']].fillna(0).astype(int)\n",
    "\n",
    "# Keep highest score as converted SAT score\n",
    "rows = (surveydata.sat > surveydata.converted_sat)\n",
    "surveydata.loc[rows, 'converted_sat'] = surveydata.loc[rows, 'sat'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set low values in all numeric cells to np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"college_gpa\", \"sat\", \"converted_sat\", \"act\", \"iq\"]\n",
    "surveydata[columns] = surveydata[columns].applymap(lambda x: x if x > 1 else np.NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format MBTI types to correct input errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_myers_briggs(mbti):\n",
    "    \"\"\"\n",
    "    Cleans Myers-Briggs string to capitalize and place letters in correct order\n",
    "    \n",
    "    Accepts string or np.NaN\n",
    "    Returns string or np.NaN\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        mbti = mbti.upper()\n",
    "    except AttributeError:\n",
    "        return np.NaN\n",
    "    return re.findall(r'E|I', mbti)[0] + re.findall(r'S|N', mbti)[0] + re.findall(r'T|F', mbti)[0] + re.findall(r'P|J', mbti)[0]\n",
    "    \n",
    "surveydata.myers_briggs = surveydata.myers_briggs.apply(clean_myers_briggs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create unique columns for elements in list columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_series_of_lists(in_series):\n",
    "    \"\"\"\n",
    "    Creates seperate boolean columns for each unique list value in Series\n",
    "    \n",
    "    Accepts list Series\n",
    "    Returns bool DataFrame\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    unique_elements = []\n",
    "    in_series = in_series.fillna(\"\")\n",
    "    clean_str = lambda x: x.strip().lower().replace(' ', '_')\n",
    "    \n",
    "    # Create a list of unique values throughout all cells in column\n",
    "    for row in in_series:\n",
    "        unique_elements.extend([clean_str(element) for element in row if clean_str(element) not in unique_elements])\n",
    "        \n",
    "                \n",
    "    def create_bool_series(cell, unique):\n",
    "        for element in cell:\n",
    "            if unique == clean_str(element):\n",
    "                return True\n",
    "            else:\n",
    "                pass\n",
    "        return False\n",
    "        \n",
    "    out_dataf = pd.DataFrame()\n",
    "    for u_element in unique_elements:\n",
    "        out_dataf.insert(0, u_element, in_series.apply(lambda x: create_bool_series(x, unique=u_element)))\n",
    "        \n",
    "    # reverse order of columns\n",
    "    return out_dataf[out_dataf.columns.tolist()[::-1]]\n",
    "\n",
    "# Convert list cells to lists\n",
    "columns = ['self_improv', 'activities', 'watched_media']\n",
    "surveydata[columns] = surveydata[columns].apply(lambda x: x.str.split(\",\"))\n",
    "\n",
    "for column in columns:\n",
    "    surveydata = pd.concat([surveydata, expand_series_of_lists(surveydata[column])], axis=1)\n",
    "\n",
    "surveydata = surveydata.drop(columns, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rename column names to make data exploration less tedious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colnames = surveydata.columns.tolist()\n",
    "\n",
    "####################\n",
    "mapping_columns = {'i_have_a_consistent_morning_routine':'routine', 'i_exercise_on_a_regular_basis':'exercise', \n",
    "                     'i_try_to_maintain_a_healthy_diet':'diet', 'i_try_to_limit_my_use_of_social_media':'limits_social_media', \n",
    "                     'i_participate_in_nofap':'nofap', 'i_keep_a_journal_for_things_like_time_management_|_personal_development/goals_|_and_idea/project_notes':'planner', \n",
    "                     \"i_keep_a_diary_for_things_like_analyzing_the_day's_activities_|_tracking_mental_health_|_and_self_reflection.\":'diary',\n",
    "                     'i_drink_energy_drinks_on_a_semi-regular_basis':'energy_drinks', 'i_practice_meditation':'meditation', 'i_take_cold_showers':'cold_showers', \n",
    "                     'i_keep_a_planner_for_things_like_time_management_|_personal_development/goals_|_and_idea/project_notes':'planner2', \n",
    "                     \"i_keep_a_journal/diary_for_things_like_analyzing_the_day's_activities_|_tracking_mental_health_|_and_self_reflection.\":'diary2', \n",
    "                     'i_drink_coffee_on_a_semi-regular_basis?':'coffee2', 'i_drink_coffee_on_a_semi-regular_basis':'coffee', 'gaming_/_mtg_/_dnd_group':'gaming_club', \n",
    "                     'drum_corps':'drum_corps', 'physical_sport_(hockey_|_soccer_|_etc.)':'plays_sports','theater_/_drama_club':'theater',\n",
    "                     'nature_hobby_(fishing_|_camping_|_etc.)':'nature_hobby','school_band_(concert_|_jazz_|_marching)':'school_band','indoor_drumline':'indoor_drumline',\n",
    "                     'stem_club_(robotics_|_it_|_etc)':'stem_club','indoor_drumline_/_wgi':'indoor_drumline2','drum_corps_/_dci':'drum_corps2'}\n",
    "####################\n",
    "\n",
    "surveydata = surveydata.rename(columns=mapping_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert (Yes, No) to (True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"social_awkward\", \"social_anxious\", \"show_up_early\", \"cluttered\", \"share_posts_often\", \"depressed\"]\n",
    "for column in columns:\n",
    "    surveydata[column] = surveydata[column].map({\"Yes\":True, \"No\":False})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine duplicate columns (coffee = coffee2, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate columns have been differentiated by appending \"2\"\n",
    "for column in [\"coffee\", \"drum_corps\", \"indoor_drumline\", \"planner\", \"diary\"]:\n",
    "    surveydata[column] = surveydata[[column, column + \"2\"]].any(axis=1)\n",
    "    surveydata = surveydata.drop([column + \"2\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop data points that are either rare or likely irrelevent\n",
    "(>50 columns is going to be impractical to work with)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colsums = surveydata.sum() #put in jupiter notebook to demonstrate need to drop low sum boolean columns (6 = lower bound) (use thresh=6? not sure how to write that yet)\n",
    "surveydata = surveydata.drop(['nofap','theater','gaming_club','stem_club','diary','flow:_the_psychology_of_optimal_experience_by_mihaly', 'mr._robot',\n",
    "                              'eternal_sunshine_of_the_spotless_mind_(2004)', \"man's_search_for_meaning_by_viktor_frankl\", 'self-reliance_by_ralph_waldo_emerson'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set missing values from datasets to NaN (instead of False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out why coffe datatype isn't boolean after following line:\n",
    "surveydata.loc[surveydata[\"survey_loc\"] == \"Implying Dum corps: electric boogaloo\", \"coffee\"] = np.NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert first 36 big5 personality score rows to range 1-5 (from range 1-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\denni\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:2963: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "def clean_big5(score):\n",
    "    \"\"\"\n",
    "    Compresses the range of given positive numberic values by two\n",
    "    \n",
    "    Accepts int or float\n",
    "    Returns int (greater than 0)\n",
    "\n",
    "    \"\"\"\n",
    "    score = score//2\n",
    "    return score if score != 0 else 1\n",
    "\n",
    "columns = ['openness', 'conscientiousness', 'extraversion', 'agreeableness', 'neuroticism']\n",
    "surveydata.iloc[0:36][columns] = surveydata.iloc[0:36][columns].applymap(clean_big5).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export data to json, excel, and csv formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "if not os.path.exists(\"../Cleaned JSON and XLSX\"):\n",
    "    os.mkdir(\"../Cleaned JSON and XLSX\")\n",
    "    \n",
    "os.chdir(\"../Cleaned JSON and XLSX\")\n",
    "\n",
    "surveydata.set_index(\"timestamp\", inplace=True)\n",
    "\n",
    "surveydata.to_json(\"surveydata.json\", orient=\"records\", lines=True, indent=4)\n",
    "surveydata.to_excel(\"surveydata.xlsx\")\n",
    "os.chdir(\"../\")\n",
    "surveydata.to_csv(\"surveydata.csv\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
